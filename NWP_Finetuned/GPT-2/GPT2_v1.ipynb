{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jtTYnhfFS6mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0b5704-d381-4610-b71f-c4ecd7abbd39",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the Dataset\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import os"
      ],
      "metadata": {
        "id": "rVBfuLnVTFGk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "LGKi4vBqYFfg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LHKk7iUkmTe",
        "outputId": "c4d71253-5c5d-481d-a113-e92e0cc86b84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 'us_bills' subset\n",
        "dataset = load_dataset(\"pile-of-law/pile-of-law\", \"us_bills\")"
      ],
      "metadata": {
        "id": "7Ha1IcXmU2PA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e50e5da-8290-4d4f-97b1-094f0b60bf95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "Overwrite dataset info from restored data version if exists.\n",
            "INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n",
            "Loading Dataset info from /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/us_bills/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/us_bills/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "Found cached dataset pile-of-law (/root/.cache/huggingface/datasets/pile-of-law___pile-of-law/us_bills/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60)\n",
            "INFO:datasets.builder:Found cached dataset pile-of-law (/root/.cache/huggingface/datasets/pile-of-law___pile-of-law/us_bills/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60)\n",
            "Loading Dataset info from /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/us_bills/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/us_bills/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of bills\n",
        "len(set(dataset['train']['text']))"
      ],
      "metadata": {
        "id": "I-Gce_eBTR9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5c8e00-20c7-4e47-c2a3-78e7cfb6b376"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84362"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset['train']['text'][10]"
      ],
      "metadata": {
        "id": "1KGs8r_lTXAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(bills):\n",
        "    clean_bills = []\n",
        "    for bill in bills:\n",
        "      # Remove all newline and tab characters\n",
        "      text = bill.replace('\\n', ' ').replace('\\t', ' ')\n",
        "      # Remove sequences of exactly three lowercase letters\n",
        "      text = re.sub(r'\\[([a-z]{1,3})\\]', ' ', text, flags=re.IGNORECASE)\n",
        "      clean_bills.append(text.lower())\n",
        "\n",
        "    return clean_bills"
      ],
      "metadata": {
        "id": "6X28PiyeTdxd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_text(dataset['train']['text'][:2]))"
      ],
      "metadata": {
        "id": "eFwBvgj5Td-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2c6444-0ccf-4506-eaa4-15a231b7ee1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['    113 s2875 is: national guard investigations transparency and improvement act of 2014 u.s. senate 2014-09-18 text/xml en pursuant to title 17 section 105 of the united states code, this file is not subject to copyright protection and is in the public domain.      ii   113th congress2d session   s. 2875   in the senate of the united states       september 18, 2014    mr. begich introduced the following bill; which was read twice and referred to the committee on armed services      a bill   to codify in law the establishment and duties of the office of complex administrative     investigations in the national guard bureau, and for other purposes.    1.short titlethis act may be cited as the national guard investigations transparency and improvement act of 2014.2.codification in law of establishment and duties of the office of complex administrative     investigations in the national guard bureau(a)in generalthere is in the office of the chief of the national guard bureau the office of complex     administrative investigations (in this section referred to as the office).(b)direction and supervisionthe office shall be under the direction and supervision of the chief of the national guard     bureau.(c)duties(1)in generalthe duties of the office shall be to undertake complex administrative investigations of matters     relating to members of the national guard when in state status, including     investigations of sexual assault involving a member of the national guard     in such status, upon the request of any of the following:(a)the chief of the national guard bureau.(b)an adjutant general of a state or territory or the district of columbia.(c)the governor  of a state or territory, or the commanding general of the national guard of the     district of columbia.(2)complex administrative investigationsfor purposes of this subsection, a complex administrative investigation is any investigation (as     specified by the chief of the national guard bureau for purposes     of this section) involving factors giving rise to unusual complexity in     investigation, including the following:(a)questions of jurisdiction between the united states and a state or territory.(b)matters requiring specialized training among investigating officers.(c)matters raising the need for an independent investigation in order to ensure fairness and     impartiality in investigation.(3)matters relating to members of the national guard in state statusthe determination whether or not a matter relates to a member of the national guard when in state     status for purposes of this section shall be made by the chief of     the national guard bureau in accordance with criteria specified by the     chief of the national guard bureau  for purposes of this section.(d)chief of national  guard bureau treatment of final reportsthe chief of the national guard bureau shall  treat any final report of the office on a matter      under this section as if such report were the report of an inspector     general of the department of defense or a military department on such     matter.(e)reports to congress(1)submittal of final reports to congressional delegationsupon the adoption by the office of a final report on an investigation undertaken by the office     pursuant to this section, the chief of the national guard bureau shall     submit such report (with any personally identifying information     appropriately redacted) to the members of congress from the state or     territory concerned.(2)annual reportsthe chief of the national guard bureau shall submit to congress each year a report on the     investigations undertaken by the office pursuant to this section during     the preceding year. each report shall include, for the year covered by     such report,  the following:(a)a summary description of the     investigations undertaken during such year,     including any trends in matters subject to investigation and in findings     as a result of investigations.(b)information, set forth by state and territory, on the investigations undertaken during such year     involving allegations of sexual assault involving a member of the national     guard.(c)such other information and matters on the investigations undertaken during such year as the chief     of the national guard bureau considers appropriate.(f)personnel and other capabilitiesthe chief of the national guard bureau shall ensure that the office maintains the personnel     and other capabilities necessary for the discharge of the duties of the     office under this section.(g)procedures and instructionsthe chief of the national guard bureau shall issue, and may from time to time update,     procedures and instructions necessary for the discharge of the duties of     the office under this section.(h)repeal of superseded instructionchief of the national guard bureau instruction cngbi 0400.01, dated july 30, 2012, shall have no     further force or effect.     ', '   110 hr 2521 ih: nursing facility fire safety act of  u.s. house of representatives 2007-05-24 text/xml en pursuant to title 17 section 105 of the united states code, this file is not subject to copyright protection and is in the public domain.       i   110th congress   1st session   h. r. 2521   in the house of representatives       may 24, 2007    mr. larson of     connecticut (for himself and mr. king of     new york) introduced the following bill; which was referred to the     committee on energy and     commerce      a bill   to provide loans and grants for fire sprinkler     retrofitting in nursing facilities.       1.short titlethis act may be cited as the     nursing facility fire safety act of     2007.   2.findings and     sense of congress    (a)findingscongress     finds the following:     (1)on     february 26, 2003, a fire at a hartford, connecticut, nursing facility without     an automatic fire sprinkler system claimed the lives of 16 patients, and on     september 27, 2003, a fire at a nashville, tennessee, nursing home without an     automatic fire sprinkler system claimed the lives of 15 patients.     (2)the national fire     protection association finds no record of a multiple death fire in a nursing     facility equipped with an automatic fire sprinkler system.     (3)an estimated 1.5     million americans reside in approximately 16,300 nursing facilities nationwide,     an estimated 20 to 30 percent of which lack an automatic fire sprinkler system.     (4)many nursing     facilities lack the financial capital to install sprinklers on their own and     must consider closure as an alternative to taking on large loans or other     financing options in order to install sprinklers.     (5)in a july 2004     report, the gao found that the substantial loss of life in the hartford     and nashville fires could have been reduced or eliminated by the presence of     properly functioning automatic sprinkler systems and that     federal oversight of nursing home compliance with fire safety standards     is inadequate.     (6)recognizing that     automatic fire sprinkler systems greatly improve the chances of survival for     older adults in the event of a fire, the national fire protection association,     with the support of the american health care association, the fire safety     community, and the nursing facility profession, recently adopted requirements     for automatic sprinklers in all existing nursing facilities.     (b)sense of     congressit is the sense of congress that—     (1)within five years,     every nursing facility in america should be equipped with automatic fire     sprinklers in order to ensure patient, resident, and staff safety; and     (2)the secretary of     health and human services (in this act referred to as the     secretary), acting through the administrator of the centers for     medicare & medicaid services should—      (a)adopt a     requirement that all nursing facilities be fully sprinklered with the support     of the nursing facility industry; and      (b)ensure that skilled nursing facilities     participating in the medicare program comply with fire safety standards, such     as those developed by the national fire protection association in the 2006 life     safety code.      3.direct loans for     fire sprinklers retrofits    (a)authoritynot later than 120 days after the date of     the enactment of this act, the secretary of health and human services shall     establish a program of direct loans to existing nursing facilities to finance     the retrofit of the facilities with an automatic fire sprinkler system. such     loans shall be made under terms and conditions specified by the     secretary.    (b)authorization of     appropriationsthere is authorized to be appropriated to carry     out this section $200,000,000 for fiscal year 2008, $100,000,000 for fiscal     year 2009, $75,000,000 for fiscal year 2010, $50,000,000 for fiscal year 2011,     and $25,000,000 for fiscal year 2012.    4.sprinkler     retrofit assistance grants    (a)authoritynot later than 120 days after the date of     the enactment of this act, the secretary of health and human services shall     establish a program to award grants to nursing facilities for the purposes of     retrofitting them with an automatic fire sprinkler system. such grants shall be     awarded under terms and conditions specified by the secretary.    (b)priorityin     awarding grants under this section, the secretary shall give a priority to     applications that demonstrate a need or hardship. in determining hardship, the     secretary may take into account factors such as the number of medicare and     medicaid patients, the age and condition of the facility, and the need for     nursing facility beds in the community involved.    (c)authorization of     appropriationsthere is authorized to be appropriated to carry     out this section $20,000,000 for each fiscal years 2008 through 2012.    5.consultation and     evaluation of alternatives    (a)consultationthe     secretary of health and human services shall consult with the secretary of     housing and urban development to determine if there are loan programs or other     funds available for retrofitting nursing facilities with an automatic fire     sprinkler system in addition to the loans and grants authorized in this     act.    (b)evaluation of     alternative remedial actionsthe secretary may evaluate, in     unique circumstances, where a nursing facility may not have an adequate     structure to retrofit the entire facility with an automatic fire sprinkler     system within a reasonable timeframe. in such an instance, the secretary shall     work with representatives of the facility to identify other remedial actions     that may include retrofitting a majority of the facility with such a system,     construction timeframes for a new or remodeled facility, or other     actions.     ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']['text'][:2]"
      ],
      "metadata": {
        "id": "rWU9ZwPhUjB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aab1c47-1ec5-48e0-de0d-f4cd426c2563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n\\t\\n\\n113 S2875 IS: National Guard Investigations Transparency and Improvement Act of 2014\\nU.S. Senate\\n2014-09-18\\ntext/xml\\nEN\\nPursuant to Title 17 Section 105 of the United States Code, this file is not subject to copyright protection and is in the public domain.\\n\\n\\n\\n\\t\\tII\\n\\t\\t113th CONGRESS2d Session\\n\\t\\tS. 2875\\n\\t\\tIN THE SENATE OF THE UNITED STATES\\n\\t\\t\\n\\t\\t\\tSeptember 18, 2014\\n\\t\\t\\tMr. Begich introduced the following bill; which was read twice and referred to the Committee on Armed Services\\n\\t\\t\\n\\t\\tA BILL\\n\\t\\tTo codify in law the establishment and duties of the Office of Complex Administrative\\n\\t\\t\\t Investigations in the National Guard Bureau, and for other purposes.\\n\\t\\n\\t1.Short titleThis Act may be cited as the National Guard Investigations Transparency and Improvement Act of 2014.2.Codification in law of establishment and duties of the Office of Complex Administrative\\n\\t\\t\\t Investigations in the National Guard Bureau(a)In generalThere is in the Office of the Chief of the National Guard Bureau the Office of Complex\\n\\t\\t\\t Administrative Investigations (in this section referred to as the Office).(b)Direction and supervisionThe Office shall be under the direction and supervision of the Chief of the National Guard\\n\\t\\t\\t Bureau.(c)Duties(1)In generalThe duties of the Office shall be to undertake complex administrative investigations of matters\\n\\t\\t\\t relating to members of the National Guard when in State status, including\\n\\t\\t\\t investigations of sexual assault involving a member of the National Guard\\n\\t\\t\\t in such status, upon the request of any of the following:(A)The Chief of the National Guard Bureau.(B)An adjutant general of a State or territory or the District of Columbia.(C)The governor  of a State or territory, or the Commanding General of the National Guard of the\\n\\t\\t\\t District of Columbia.(2)Complex administrative investigationsFor purposes of this subsection, a complex administrative investigation is any investigation (as\\n\\t\\t\\t specified by the Chief of the National Guard Bureau for purposes\\n\\t\\t\\t of this section) involving factors giving rise to unusual complexity in\\n\\t\\t\\t investigation, including the following:(A)Questions of jurisdiction between the United States and a State or territory.(B)Matters requiring specialized training among investigating officers.(C)Matters raising the need for an independent investigation in order to ensure fairness and\\n\\t\\t\\t impartiality in investigation.(3)Matters relating to members of the National Guard in State statusThe determination whether or not a matter relates to a member of the National Guard when in State\\n\\t\\t\\t status for purposes of this section shall be made by the Chief of\\n\\t\\t\\t the National Guard Bureau in accordance with criteria specified by the\\n\\t\\t\\t Chief of the National Guard Bureau  for purposes of this section.(d)Chief of National  Guard Bureau treatment of final reportsThe Chief of the National Guard Bureau shall  treat any final report of the Office on a matter \\n\\t\\t\\t under this section as if such report were the report of an Inspector\\n\\t\\t\\t General of the Department of Defense or a military department on such\\n\\t\\t\\t matter.(e)Reports to Congress(1)Submittal of final reports to congressional delegationsUpon the adoption by the Office of a final report on an investigation undertaken by the Office\\n\\t\\t\\t pursuant to this section, the Chief of the National Guard Bureau shall\\n\\t\\t\\t submit such report (with any personally identifying information\\n\\t\\t\\t appropriately redacted) to the members of Congress from the State or\\n\\t\\t\\t territory concerned.(2)Annual reportsThe Chief of the National Guard Bureau shall submit to Congress each year a report on the\\n\\t\\t\\t investigations undertaken by the Office pursuant to this section during\\n\\t\\t\\t the preceding year. Each report shall include, for the year covered by\\n\\t\\t\\t such report,  the following:(A)A summary description of the\\n\\t\\t\\t investigations undertaken during such year,\\n\\t\\t\\t including any trends in matters subject to investigation and in findings\\n\\t\\t\\t as a result of investigations.(B)Information, set forth by State and territory, on the investigations undertaken during such year\\n\\t\\t\\t involving allegations of sexual assault involving a member of the National\\n\\t\\t\\t Guard.(C)Such other information and matters on the investigations undertaken during such year as the Chief\\n\\t\\t\\t of the National Guard Bureau considers appropriate.(f)Personnel and other capabilitiesThe Chief of the National Guard Bureau shall ensure that the Office maintains the personnel\\n\\t\\t\\t and other capabilities necessary for the discharge of the duties of the\\n\\t\\t\\t Office under this section.(g)Procedures and instructionsThe Chief of the National Guard Bureau shall issue, and may from time to time update,\\n\\t\\t\\t procedures and instructions necessary for the discharge of the duties of\\n\\t\\t\\t the Office under this section.(h)Repeal of superseded instructionChief of the National Guard Bureau Instruction CNGBI 0400.01, dated July 30, 2012, shall have no\\n\\t\\t\\t further force or effect.\\n\\t\\t\\t\\n',\n",
              " '\\n\\n\\n110 HR 2521 IH: Nursing Facility Fire Safety Act of\\n\\nU.S. House of Representatives\\n2007-05-24\\ntext/xml\\nEN\\nPursuant to Title 17 Section 105 of the United States Code, this file is not subject to copyright protection and is in the public domain.\\n\\n\\n\\t\\n\\t\\tI\\n\\t\\t110th CONGRESS\\n\\t\\t1st Session\\n\\t\\tH. R. 2521\\n\\t\\tIN THE HOUSE OF REPRESENTATIVES\\n\\t\\t\\n\\t\\t\\tMay 24, 2007\\n\\t\\t\\tMr. Larson of\\n\\t\\t\\t Connecticut (for himself and Mr. King of\\n\\t\\t\\t New York) introduced the following bill; which was referred to the\\n\\t\\t\\t Committee on Energy and\\n\\t\\t\\t Commerce\\n\\t\\t\\n\\t\\tA BILL\\n\\t\\tTo provide loans and grants for fire sprinkler\\n\\t\\t  retrofitting in nursing facilities.\\n\\t\\n\\t\\n\\t\\t1.Short titleThis Act may be cited as the\\n\\t\\t\\t Nursing Facility Fire Safety Act of\\n\\t\\t\\t 2007.\\n\\t\\t2.Findings and\\n\\t\\t\\t Sense of Congress\\n\\t\\t\\t(a)FindingsCongress\\n\\t\\t\\t finds the following:\\n\\t\\t\\t\\t(1)On\\n\\t\\t\\t February 26, 2003, a fire at a Hartford, Connecticut, nursing facility without\\n\\t\\t\\t an automatic fire sprinkler system claimed the lives of 16 patients, and on\\n\\t\\t\\t September 27, 2003, a fire at a Nashville, Tennessee, nursing home without an\\n\\t\\t\\t automatic fire sprinkler system claimed the lives of 15 patients.\\n\\t\\t\\t\\t(2)The National Fire\\n\\t\\t\\t Protection Association finds no record of a multiple death fire in a nursing\\n\\t\\t\\t facility equipped with an automatic fire sprinkler system.\\n\\t\\t\\t\\t(3)An estimated 1.5\\n\\t\\t\\t million Americans reside in approximately 16,300 nursing facilities nationwide,\\n\\t\\t\\t an estimated 20 to 30 percent of which lack an automatic fire sprinkler system.\\n\\t\\t\\t\\t(4)Many nursing\\n\\t\\t\\t facilities lack the financial capital to install sprinklers on their own and\\n\\t\\t\\t must consider closure as an alternative to taking on large loans or other\\n\\t\\t\\t financing options in order to install sprinklers.\\n\\t\\t\\t\\t(5)In a July 2004\\n\\t\\t\\t report, the GAO found that the substantial loss of life in the Hartford\\n\\t\\t\\t and Nashville fires could have been reduced or eliminated by the presence of\\n\\t\\t\\t properly functioning automatic sprinkler systems and that\\n\\t\\t\\t Federal oversight of nursing home compliance with fire safety standards\\n\\t\\t\\t is inadequate.\\n\\t\\t\\t\\t(6)Recognizing that\\n\\t\\t\\t automatic fire sprinkler systems greatly improve the chances of survival for\\n\\t\\t\\t older adults in the event of a fire, the National Fire Protection Association,\\n\\t\\t\\t with the support of the American Health Care Association, the fire safety\\n\\t\\t\\t community, and the nursing facility profession, recently adopted requirements\\n\\t\\t\\t for automatic sprinklers in all existing nursing facilities.\\n\\t\\t\\t\\t(b)Sense of\\n\\t\\t\\t CongressIt is the sense of Congress that—\\n\\t\\t\\t\\t(1)within five years,\\n\\t\\t\\t every nursing facility in America should be equipped with automatic fire\\n\\t\\t\\t sprinklers in order to ensure patient, resident, and staff safety; and\\n\\t\\t\\t\\t(2)the Secretary of\\n\\t\\t\\t Health and Human Services (in this Act referred to as the\\n\\t\\t\\t Secretary), acting through the Administrator of the Centers for\\n\\t\\t\\t Medicare & Medicaid Services should—\\n\\t\\t\\t\\t\\t(A)adopt a\\n\\t\\t\\t requirement that all nursing facilities be fully sprinklered with the support\\n\\t\\t\\t of the nursing facility industry; and\\n\\t\\t\\t\\t\\t(B)ensure that skilled nursing facilities\\n\\t\\t\\t participating in the Medicare program comply with fire safety standards, such\\n\\t\\t\\t as those developed by the National Fire Protection Association in the 2006 Life\\n\\t\\t\\t Safety Code.\\n\\t\\t\\t\\t\\t3.Direct loans for\\n\\t\\t\\t fire sprinklers retrofits\\n\\t\\t\\t(a)AuthorityNot later than 120 days after the date of\\n\\t\\t\\t the enactment of this Act, the Secretary of Health and Human Services shall\\n\\t\\t\\t establish a program of direct loans to existing nursing facilities to finance\\n\\t\\t\\t the retrofit of the facilities with an automatic fire sprinkler system. Such\\n\\t\\t\\t loans shall be made under terms and conditions specified by the\\n\\t\\t\\t Secretary.\\n\\t\\t\\t(b)Authorization of\\n\\t\\t\\t appropriationsThere is authorized to be appropriated to carry\\n\\t\\t\\t out this section $200,000,000 for fiscal year 2008, $100,000,000 for fiscal\\n\\t\\t\\t year 2009, $75,000,000 for fiscal year 2010, $50,000,000 for fiscal year 2011,\\n\\t\\t\\t and $25,000,000 for fiscal year 2012.\\n\\t\\t\\t4.Sprinkler\\n\\t\\t\\t retrofit assistance grants\\n\\t\\t\\t(a)AuthorityNot later than 120 days after the date of\\n\\t\\t\\t the enactment of this Act, the Secretary of Health and Human Services shall\\n\\t\\t\\t establish a program to award grants to nursing facilities for the purposes of\\n\\t\\t\\t retrofitting them with an automatic fire sprinkler system. Such grants shall be\\n\\t\\t\\t awarded under terms and conditions specified by the Secretary.\\n\\t\\t\\t(b)PriorityIn\\n\\t\\t\\t awarding grants under this section, the Secretary shall give a priority to\\n\\t\\t\\t applications that demonstrate a need or hardship. In determining hardship, the\\n\\t\\t\\t Secretary may take into account factors such as the number of Medicare and\\n\\t\\t\\t Medicaid patients, the age and condition of the facility, and the need for\\n\\t\\t\\t nursing facility beds in the community involved.\\n\\t\\t\\t(c)Authorization of\\n\\t\\t\\t appropriationsThere is authorized to be appropriated to carry\\n\\t\\t\\t out this section $20,000,000 for each fiscal years 2008 through 2012.\\n\\t\\t\\t5.Consultation and\\n\\t\\t\\t evaluation of alternatives\\n\\t\\t\\t(a)ConsultationThe\\n\\t\\t\\t Secretary of Health and Human Services shall consult with the Secretary of\\n\\t\\t\\t Housing and Urban Development to determine if there are loan programs or other\\n\\t\\t\\t funds available for retrofitting nursing facilities with an automatic fire\\n\\t\\t\\t sprinkler system in addition to the loans and grants authorized in this\\n\\t\\t\\t Act.\\n\\t\\t\\t(b)Evaluation of\\n\\t\\t\\t alternative remedial actionsThe Secretary may evaluate, in\\n\\t\\t\\t unique circumstances, where a nursing facility may not have an adequate\\n\\t\\t\\t structure to retrofit the entire facility with an automatic fire sprinkler\\n\\t\\t\\t system within a reasonable timeframe. In such an instance, the Secretary shall\\n\\t\\t\\t work with representatives of the facility to identify other remedial actions\\n\\t\\t\\t that may include retrofitting a majority of the facility with such a system,\\n\\t\\t\\t construction timeframes for a new or remodeled facility, or other\\n\\t\\t\\t actions.\\n\\t\\t\\t\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "faI1dEEjj8K0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(text, model=model, tokenizer=tokenizer):\n",
        "    \"\"\"\n",
        "    Predicts the next word for a given text using GPT-2.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text with truncation to max_length\n",
        "    input_ids = text #.unsqueeze(0) #tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "\n",
        "    #### print(\"Predict next word, input shape: \", input_ids.shape)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #print(device)\n",
        "    #print(\"input_ids device: \", input_ids.device)\n",
        "    # Generate logits\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids.to(device))\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Predict the next token\n",
        "    predicted_token_id = torch.argmax(logits[:, -1, :], dim=-1).item()\n",
        "    predicted_token = tokenizer.decode(predicted_token_id)\n",
        "\n",
        "    return predicted_token\n",
        "\n",
        "\n",
        "    # Predict the next token\n",
        "    predicted_token_id = torch.argmax(logits[:, -1, :], dim=-1).item()\n",
        "    predicted_token = tokenizer.decode(predicted_token_id)\n",
        "\n",
        "    return predicted_token\n"
      ],
      "metadata": {
        "id": "UvcK6RLKVEdv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_every_n_words(bill_text, bill_number, model, interval_min=20, interval_max=40):\n",
        "    words = tokenizer.encode(bill_text, return_tensors=\"pt\", truncation=True, max_length=1024) #bill_text.split()\n",
        "    n = words.shape[1]\n",
        "    results = []\n",
        "\n",
        "    #### print(words.shape)\n",
        "    #### print(words)\n",
        "\n",
        "    random.seed(42)\n",
        "\n",
        "    # Start from the first 20 words and predict every 20-40 words\n",
        "    i = 15\n",
        "    while i < n and i < 1024:\n",
        "        # Prepare the input chunk (first i words)\n",
        "        text_chunk = words[:,:i] #' '.join(words[:i])\n",
        "        actual_next_word = words[:,i]\n",
        "        #### print(\"Current text chunk: \",  tokenizer.decode(text_chunk[0], skip_special_tokens=True))\n",
        "        # Predict the next word\n",
        "        predicted_next_word = predict_next_word(text_chunk, model=model)\n",
        "        english_actual_next_word = tokenizer.decode(actual_next_word, skip_special_tokens=True)\n",
        "        # Store the results: actual, predicted, and the number of words in the input text\n",
        "        res = {\n",
        "            \"bill_number\": bill_number,\n",
        "            \"input_text_length\": i,\n",
        "            \"actual_next_word\": english_actual_next_word,\n",
        "            \"predicted_next_word\": predicted_next_word,\n",
        "            \"correct_prediction\": english_actual_next_word.lower() == predicted_next_word.lower()\n",
        "        }\n",
        "        results.append(res)\n",
        "\n",
        "        #### print(\"Appending row: \", res)\n",
        "\n",
        "        # Move to the next interval of 20-40 words\n",
        "        interval = random.randint(interval_min, interval_max)\n",
        "        i += interval\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "YtRwA0FmWfZP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bills(bills, model):\n",
        "    overall_predictions = []\n",
        "    total_correct = 0\n",
        "    total_total = 0\n",
        "\n",
        "    for idx, bill_text in enumerate(bills):\n",
        "        print(f\"Processing bill {idx} of length {len(bill_text)} characters...\")\n",
        "\n",
        "        # Get the results from predict_every_n_words\n",
        "        results = predict_every_n_words(bill_text, idx, model=model)\n",
        "        display(pd.DataFrame(results))\n",
        "        # Extend the overall predictions list with the results from this bill\n",
        "        overall_predictions.extend(results)\n",
        "\n",
        "        # Calculate accuracy for the current bill\n",
        "        correct_predictions = sum(1 for result in results if result['correct_prediction'])\n",
        "        bill_accuracy = correct_predictions / len(results) if len(results) > 0 else 0\n",
        "\n",
        "        print(f\"Bill {idx} accuracy: {bill_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "        # Track the total correct and total predictions\n",
        "        total_correct += correct_predictions\n",
        "        total_total += len(results)\n",
        "\n",
        "    df_overall_predictions = pd.DataFrame(overall_predictions) #dataframe\n",
        "\n",
        "    # Calculate overall accuracy for all bills\n",
        "    overall_accuracy = total_correct / total_total if total_total > 0 else 0\n",
        "    print(f\"Overall accuracy for all bills: {overall_accuracy * 100:.2f}%\")\n",
        "\n",
        "    return df_overall_predictions\n"
      ],
      "metadata": {
        "id": "itGcf0uBYzVS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iRq-EGmIY8o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text for both train and validation splits\n",
        "#cleaned_train = clean_text(dataset[\"train\"][\"text\"])\n",
        "cleaned_validation = clean_text(dataset[\"validation\"][\"text\"][:10]) #subset - 5 samples only\n",
        "\n",
        "df_predictions_bills = evaluate_bills(cleaned_validation, model)"
      ],
      "metadata": {
        "id": "v3GIgGcHb4HJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91ec72b3-032e-4468-d9a9-f8faba5ef0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing bill 0 of length 6705 characters...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ebb22233349d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcleaned_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#subset - 5 samples only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_predictions_bills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_bills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-c13a01751c76>\u001b[0m in \u001b[0;36mevaluate_bills\u001b[0;34m(bills, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Get the results from predict_every_n_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_every_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbill_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Extend the overall predictions list with the results from this bill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3f775d1ab62f>\u001b[0m in \u001b[0;36mpredict_every_n_words\u001b[0;34m(bill_text, bill_number, model, interval_min, interval_max)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#### print(\"Current text chunk: \",  tokenizer.decode(text_chunk[0], skip_special_tokens=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Predict the next word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpredicted_next_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0menglish_actual_next_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_next_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Store the results: actual, predicted, and the number of words in the input text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-b60aa5e7d680>\u001b[0m in \u001b[0;36mpredict_next_word\u001b[0;34m(text, model, tokenizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Generate logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1272\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions_bills2 = evaluate_bills(cleaned_validation, model)"
      ],
      "metadata": {
        "id": "IslOBMtY3o9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4b71767-a999-4bed-acab-4aa4cd6600f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing bill 0 of length 48228 characters...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    bill_number  input_text_length actual_next_word predicted_next_word  \\\n",
              "0             0                 15              the                 the   \n",
              "1             0                 55              the                 the   \n",
              "2             0                 78                i                       \n",
              "3             0                 98           united              united   \n",
              "4             0                126           second              second   \n",
              "5             0                153                                        \n",
              "6             0                180           budget                       \n",
              "7             0                204              for                 for   \n",
              "8             0                227                (                       \n",
              "9             0                264                1                   1   \n",
              "10            0                286              ary                 for   \n",
              "11            0                324              201                 102   \n",
              "12            0                357                .                   .   \n",
              "13            0                378            effic                 the   \n",
              "14            0                398          savings                 and   \n",
              "15            0                420              500                   2   \n",
              "16            0                446                .                   .   \n",
              "17            0                473         determin                  of   \n",
              "18            0                509           levels                   .   \n",
              "19            0                548         exercise          limitation   \n",
              "20            0                568              the                 the   \n",
              "21            0                605                                        \n",
              "22            0                631               29                  29   \n",
              "23            0                671                7                 000   \n",
              "24            0                708              000                 000   \n",
              "25            0                741              000                 000   \n",
              "26            0                768                3                   4   \n",
              "27            0                802               20                  20   \n",
              "28            0                840            which               which   \n",
              "29            0                868                .                   ,   \n",
              "30            0                888                :                   :   \n",
              "31            0                913                :                   :   \n",
              "32            0                946                                    −   \n",
              "33            0                976                f                   f   \n",
              "34            0               1004               of                  of   \n",
              "\n",
              "    correct_prediction  \n",
              "0                 True  \n",
              "1                 True  \n",
              "2                False  \n",
              "3                 True  \n",
              "4                 True  \n",
              "5                 True  \n",
              "6                False  \n",
              "7                 True  \n",
              "8                False  \n",
              "9                 True  \n",
              "10               False  \n",
              "11               False  \n",
              "12                True  \n",
              "13               False  \n",
              "14               False  \n",
              "15               False  \n",
              "16                True  \n",
              "17               False  \n",
              "18               False  \n",
              "19               False  \n",
              "20                True  \n",
              "21                True  \n",
              "22                True  \n",
              "23               False  \n",
              "24                True  \n",
              "25                True  \n",
              "26               False  \n",
              "27                True  \n",
              "28                True  \n",
              "29               False  \n",
              "30                True  \n",
              "31                True  \n",
              "32               False  \n",
              "33                True  \n",
              "34                True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b29510fc-57b8-4fd9-973a-125e26d864fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bill_number</th>\n",
              "      <th>input_text_length</th>\n",
              "      <th>actual_next_word</th>\n",
              "      <th>predicted_next_word</th>\n",
              "      <th>correct_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>i</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>united</td>\n",
              "      <td>united</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>126</td>\n",
              "      <td>second</td>\n",
              "      <td>second</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>153</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>budget</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>204</td>\n",
              "      <td>for</td>\n",
              "      <td>for</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>227</td>\n",
              "      <td>(</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>264</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>286</td>\n",
              "      <td>ary</td>\n",
              "      <td>for</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>324</td>\n",
              "      <td>201</td>\n",
              "      <td>102</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>357</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>378</td>\n",
              "      <td>effic</td>\n",
              "      <td>the</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>398</td>\n",
              "      <td>savings</td>\n",
              "      <td>and</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>446</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>473</td>\n",
              "      <td>determin</td>\n",
              "      <td>of</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>509</td>\n",
              "      <td>levels</td>\n",
              "      <td>.</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>548</td>\n",
              "      <td>exercise</td>\n",
              "      <td>limitation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>568</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>605</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>631</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>671</td>\n",
              "      <td>7</td>\n",
              "      <td>000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>708</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>741</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>768</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>802</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>840</td>\n",
              "      <td>which</td>\n",
              "      <td>which</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>868</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>888</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>913</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>946</td>\n",
              "      <td></td>\n",
              "      <td>−</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "      <td>976</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0</td>\n",
              "      <td>1004</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b29510fc-57b8-4fd9-973a-125e26d864fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b29510fc-57b8-4fd9-973a-125e26d864fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b29510fc-57b8-4fd9-973a-125e26d864fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a1985a6e-f9c8-4740-81f2-f07169a8836b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1985a6e-f9c8-4740-81f2-f07169a8836b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a1985a6e-f9c8-4740-81f2-f07169a8836b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_predictions_bills2 = evaluate_bills(cleaned_validation, model)\",\n  \"rows\": 35,\n  \"fields\": [\n    {\n      \"column\": \"bill_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_text_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 300,\n        \"min\": 15,\n        \"max\": 1004,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual_next_word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_next_word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \" the\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_prediction\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bill 0 accuracy: 57.14%\n",
            "\n",
            "Overall accuracy for all bills: 57.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VYnr2LV353u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Fine Tuning ####"
      ],
      "metadata": {
        "id": "M0-wi4OO35_H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjGpt5GyrmEL",
        "outputId": "f7ef83ba-24bc-4ed6-c9fe-6a19f6a4b758"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "3SzaaJik2ebD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text for both train and validation splits\n",
        "cleaned_train = clean_text(dataset[\"train\"][\"text\"][:2])\n",
        "cleaned_validation = clean_text(dataset[\"validation\"][\"text\"][1:2]) #subset - 5 samples only\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "LkiLx7BbKIxx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom function to generate chunks from documents\n",
        "def generate_chunks_from_text(text, min_length=100, max_length=1024, tokenizer = tokenizer):\n",
        "    print(\"I be\")\n",
        "    tokens = tokenizer.encode(text, truncation=False, padding=False)  # Encode without truncation\n",
        "    print(\"Doubting\")\n",
        "    chunks = []\n",
        "    while len(tokens) >= min_length:\n",
        "        # Generate a random chunk length between min_length and max_length (or remaining tokens)\n",
        "        chunk_length = random.randint(min_length, min(max_length, len(tokens)))  # Random length for each chunk\n",
        "        chunk = tokens[:chunk_length]\n",
        "        chunks.append(chunk)\n",
        "        tokens = tokens[chunk_length:]  # Remove the processed chunk from the tokens\n",
        "    print(\"Generated n chunks: \", len(chunks))\n",
        "    return chunks\n",
        "\n",
        "# Function to manually expand the dataset by adding multiple rows for each document\n",
        "def split_into_chunks(train_bills, min_length=100, max_length=1024, tokenizer=tokenizer):\n",
        "    all_input_ids = []\n",
        "    all_labels = []\n",
        "    all_attention_masks = []  # To store attention masks\n",
        "\n",
        "    for text in train_bills:\n",
        "        # Split the document into multiple chunks\n",
        "        chunks = generate_chunks_from_text(text, min_length, max_length, tokenizer)\n",
        "        for chunk in chunks:\n",
        "            all_input_ids.append(chunk)\n",
        "            all_labels.append(chunk)  # For causal language modeling, labels are the same as input_ids\n",
        "\n",
        "            # Generate attention mask: 1 for real tokens, 0 for padding (for now, we assume no padding in chunks)\n",
        "            attention_mask = [1] * len(chunk)\n",
        "            all_attention_masks.append(attention_mask)\n",
        "\n",
        "    print(\"Raw input ids and label ids dims:\", len(all_input_ids), \" x \", len(all_input_ids[0]), \" or \", len(all_input_ids[1]), ' and ', len(all_labels), ' x ', len(all_labels[0]), ' or ', len(all_labels[1]))\n",
        "\n",
        "    # Now, pad the sequences to ensure they have consistent lengths\n",
        "    input_ids_padded = tokenizer.pad(\n",
        "        {\"input_ids\": all_input_ids},  # Only need to pad input_ids\n",
        "        padding='max_length',  # Pad to the longest sequence in the batch\n",
        "        max_length=max_length,  # Set max length\n",
        "        return_tensors=\"pt\"  # Return as pytorch tensors\n",
        "    )\n",
        "\n",
        "    # Pad labels as well\n",
        "    labels_padded = tokenizer.pad(\n",
        "        {\"input_ids\": all_labels},  # Same padding as input_ids\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Pad the attention masks (1 for real tokens, 0 for padding)\n",
        "    attention_masks_padded = tokenizer.pad(\n",
        "        {\"input_ids\": all_attention_masks},  # Same padding for attention masks\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    print(\"In split into chunks, size of all 3 columns: \", input_ids_padded['input_ids'].shape)\n",
        "    # Return the padded dataset with attention masks\n",
        "    return {\n",
        "        \"input_ids\": input_ids_padded[\"input_ids\"],\n",
        "        \"labels\": labels_padded[\"input_ids\"],\n",
        "        \"attention_mask\": attention_masks_padded[\"input_ids\"]  # Add the attention mask\n",
        "    }\n",
        "\n",
        "# Function to train the model with explicit parameters\n",
        "def train_model(clean_tr, clean_val, tokenizer, model, epochs=3, output_dir=\"./drive/MyDrive/nlp_proj_results\"):\n",
        "    # Step 1: Clean the text data\n",
        "    train_bills = clean_tr\n",
        "    val_bills = clean_val\n",
        "\n",
        "    # Set padding token to eos_token\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Step 2: Tokenize the cleaned data\n",
        "    # random.seed(42)\n",
        "    # def tokenize_function(examples):\n",
        "    #     #return tokenizer(examples['text'], return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=1024)\n",
        "    #     min_length = 100\n",
        "    #     max_length = 1024\n",
        "    #     all_input_ids = []\n",
        "    #     all_labels = []\n",
        "\n",
        "    #     for text in examples['text']:\n",
        "    #         tokens = tokenizer.encode(text, truncation=False, padding=False)  # Encode without truncation\n",
        "    #         text_length = len(tokens)\n",
        "\n",
        "    #         # Split the document into multiple chunks of random lengths\n",
        "    #         chunks = []\n",
        "    #         while len(tokens) >= min_length:\n",
        "    #             # Generate a random chunk length between min_length and max_length (or remaining tokens)\n",
        "    #             random_max_length = random.randint(min_length, min(max_length, len(tokens)))  # Random length for each chunk\n",
        "    #             chunk = tokens[:random_max_length]\n",
        "    #             chunks.append(chunk)\n",
        "    #             tokens = tokens[random_max_length:]  # Remove the processed chunk from the tokens\n",
        "\n",
        "    #         # Append the chunks for this text\n",
        "    #         for chunk in chunks:\n",
        "    #             all_input_ids.append(chunk)  # Add the chunk as an input example\n",
        "    #             all_labels.append(chunk)\n",
        "\n",
        "    #     # Return the tokenized chunks as input_ids\n",
        "    #     res = {\n",
        "    #         \"input_ids\": all_input_ids,\n",
        "    #         \"labels\": all_labels  # For causal language modeling, labels are the same as input_ids\n",
        "    #     }\n",
        "    #     print(\"Tokenize fn returning res: \", len(res['input_ids']), 'by ', len(res['input_ids'][1]))\n",
        "    #     #print(\"Input ids of shape: \", )\n",
        "    #     return res\n",
        "\n",
        "    # Convert lists into dataset format\n",
        "    train_dataset = Dataset.from_dict({\"text\": train_bills})\n",
        "    #val_dataset = Dataset.from_dict({\"text\": val_bills})\n",
        "\n",
        "    # Tokenize the datasets\n",
        "    train_dataset = Dataset.from_dict(split_into_chunks(train_bills, min_length=100, max_length=1024))\n",
        "    #print(\"Train dataset size: \", train_dataset['input_ids'].shape)\n",
        "    print(\"Train dataset: \", train_dataset)\n",
        "    #train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    #val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # Remove original text column since we now have tokenized data\n",
        "    #train_dataset = train_dataset.remove_columns([\"text\"])\n",
        "    #val_dataset = val_dataset.remove_columns([\"text\"])\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "      tokenizer=tokenizer,\n",
        "      mlm=False  # This is not a masked language model task, so set to False\n",
        "    )\n",
        "\n",
        "    # Step 3: Define Training Arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,              # Directory to save model checkpoints\n",
        "        #evaluation_strategy=\"epoch\",         # Evaluate after every epoch\n",
        "        #learning_rate=learning_rate,        # Learning rate\n",
        "        #per_device_train_batch_size=batch_size,        # Batch size per device (adjust based on GPU memory)\n",
        "        #per_device_eval_batch_size=batch_size,         # Batch size for evaluation\n",
        "        num_train_epochs=epochs,                   # Number of training epochs\n",
        "        #weight_decay=0.01,                    # Weight decay for regularization\n",
        "        logging_dir=\"./logs\",                 # Directory to save logs\n",
        "        logging_steps=100,                    # Log every 100 steps\n",
        "    )\n",
        "\n",
        "    # Step 4: Initialize the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,                          # The pre-trained model\n",
        "        args=training_args,                   # The training arguments\n",
        "        data_collator=data_collator,          # Data collator for batching\n",
        "        train_dataset=train_dataset,          # The training dataset\n",
        "    )\n",
        "\n",
        "    #train_dataloader = DataLoader(train_dataset, batch_size=16, collate_fn=data_collator)\n",
        "    #print(\"Train dataloader: \", train_dataloader.keys())\n",
        "    # Inspect the first batch\n",
        "    # for batch in train_dataloader:\n",
        "    #     print(f\"Batch keys: {batch.keys()}\")  # Check the keys in the batch\n",
        "    #     print(f\"Batch input_ids shape: {batch['input_ids'].shape}\")\n",
        "    #     print(f\"Batch attention_mask shape: {batch['attention_mask'].shape}\")\n",
        "    #     break  # Only check the first batch\n",
        "\n",
        "    # print(\"Train dataset: \", train_dataloader)\n",
        "    # # Fetch and print the first batch\n",
        "    # for batch in train_dataloader:\n",
        "    #     # print(f\"Batch input:\")\n",
        "\n",
        "    #     # # Print input_ids\n",
        "    #     # print(\"input_ids:\", batch['input_ids'])\n",
        "    #     # print(\"Shape of input_ids:\", batch['input_ids'].shape)\n",
        "\n",
        "    #     # # Decode the input_ids to see the actual text\n",
        "    #     # decoded_inputs = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['input_ids']]\n",
        "    #     # print(\"Decoded inputs:\", decoded_inputs)\n",
        "\n",
        "    #     # # Print attention_mask (if it exists)\n",
        "    #     # if 'attention_mask' in batch:\n",
        "    #     #     print(\"attention_mask:\", batch['attention_mask'])\n",
        "\n",
        "    #     # # Print labels (they should be the same as input_ids for causal LM)\n",
        "    #     # print(\"labels:\", batch['labels'])\n",
        "    #     # decoded_labels = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['labels']]\n",
        "    #     # print(\"Decoded labels:\", decoded_labels)\n",
        "\n",
        "    #     print(\"=\"*50)  # Separator for batch prints\n",
        "\n",
        "    # Step 5: Start training\n",
        "    trainer.train()\n",
        "\n",
        "    # Step 6: Evaluate the model after training\n",
        "    # eval_results = trainer.evaluate()\n",
        "    # print(f\"Evaluation Results: {eval_results}\")\n",
        "\n",
        "    # Step 7: Save the fine-tuned model\n",
        "    model.save_pretrained(output_dir)\n",
        "    #tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    # Return only the fine-tuned model (no need to return the tokenizer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "GT-xN_wpHVYe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.cuda.empty_cache()\n",
        "fine_tuned_gpt2 = train_model(cleaned_train, cleaned_validation, tokenizer, model, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "gjC0VtdJMJ2b",
        "outputId": "deb23197-a045-4e2b-ea5f-e3db085401aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Failed to cast a sequence to int8. Falling back to int64.\n",
            "INFO:datasets.arrow_writer:Failed to cast a sequence to int8. Falling back to int64.\n",
            "Failed to cast a sequence to int8. Falling back to int64.\n",
            "INFO:datasets.arrow_writer:Failed to cast a sequence to int8. Falling back to int64.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I be\n",
            "Doubting\n",
            "Generated n chunks:  2\n",
            "I be\n",
            "Doubting\n",
            "Generated n chunks:  3\n",
            "Raw input ids and label ids dims: 5  x  992  or  101  and  5  x  992  or  101\n",
            "In split into chunks, size of all 3 columns:  torch.Size([5, 1024])\n",
            "Train dataset:  Dataset({\n",
            "    features: ['input_ids', 'labels', 'attention_mask'],\n",
            "    num_rows: 5\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 01:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions_bills_finetuned = evaluate_bills(cleaned_validation, model=fine_tuned_gpt2)"
      ],
      "metadata": {
        "id": "sXik2egcMKyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8585ec5-d96d-4f78-ee69-a95fe5c49c58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing bill 0 of length 48228 characters...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    bill_number  input_text_length actual_next_word predicted_next_word  \\\n",
              "0             0                 15              the              fiscal   \n",
              "1             0                 55              the                 the   \n",
              "2             0                 78                i                       \n",
              "3             0                 98           united              united   \n",
              "4             0                126           second              second   \n",
              "5             0                153                                        \n",
              "6             0                180           budget                       \n",
              "7             0                204              for                 for   \n",
              "8             0                227                (                       \n",
              "9             0                264                1                   1   \n",
              "10            0                286              ary                 for   \n",
              "11            0                324              201                 102   \n",
              "12            0                357                .                   .   \n",
              "13            0                378            effic              fiscal   \n",
              "14            0                398          savings                care   \n",
              "15            0                420              500                 400   \n",
              "16            0                446                .                   .   \n",
              "17            0                473         determin                  of   \n",
              "18            0                509           levels                   .   \n",
              "19            0                548         exercise      appropriations   \n",
              "20            0                568              the                 the   \n",
              "21            0                605                                        \n",
              "22            0                631               29                  29   \n",
              "23            0                671                7                 000   \n",
              "24            0                708              000                 000   \n",
              "25            0                741              000                 000   \n",
              "26            0                768                3                   3   \n",
              "27            0                802               20                  20   \n",
              "28            0                840            which               which   \n",
              "29            0                868                .                   ,   \n",
              "30            0                888                :                   :   \n",
              "31            0                913                :                   :   \n",
              "32            0                946                                    $   \n",
              "33            0                976                f                   f   \n",
              "34            0               1004               of                  of   \n",
              "\n",
              "    correct_prediction  \n",
              "0                False  \n",
              "1                 True  \n",
              "2                False  \n",
              "3                 True  \n",
              "4                 True  \n",
              "5                 True  \n",
              "6                False  \n",
              "7                 True  \n",
              "8                False  \n",
              "9                 True  \n",
              "10               False  \n",
              "11               False  \n",
              "12                True  \n",
              "13               False  \n",
              "14               False  \n",
              "15               False  \n",
              "16                True  \n",
              "17               False  \n",
              "18               False  \n",
              "19               False  \n",
              "20                True  \n",
              "21                True  \n",
              "22                True  \n",
              "23               False  \n",
              "24                True  \n",
              "25                True  \n",
              "26                True  \n",
              "27                True  \n",
              "28                True  \n",
              "29               False  \n",
              "30                True  \n",
              "31                True  \n",
              "32               False  \n",
              "33                True  \n",
              "34                True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26ce9993-51a9-4aca-a902-50b5811c6a95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bill_number</th>\n",
              "      <th>input_text_length</th>\n",
              "      <th>actual_next_word</th>\n",
              "      <th>predicted_next_word</th>\n",
              "      <th>correct_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>the</td>\n",
              "      <td>fiscal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>i</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>united</td>\n",
              "      <td>united</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>126</td>\n",
              "      <td>second</td>\n",
              "      <td>second</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>153</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>budget</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>204</td>\n",
              "      <td>for</td>\n",
              "      <td>for</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>227</td>\n",
              "      <td>(</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>264</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>286</td>\n",
              "      <td>ary</td>\n",
              "      <td>for</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>324</td>\n",
              "      <td>201</td>\n",
              "      <td>102</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>357</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>378</td>\n",
              "      <td>effic</td>\n",
              "      <td>fiscal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>398</td>\n",
              "      <td>savings</td>\n",
              "      <td>care</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>500</td>\n",
              "      <td>400</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>446</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>473</td>\n",
              "      <td>determin</td>\n",
              "      <td>of</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>509</td>\n",
              "      <td>levels</td>\n",
              "      <td>.</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>548</td>\n",
              "      <td>exercise</td>\n",
              "      <td>appropriations</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>568</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>605</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>631</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>671</td>\n",
              "      <td>7</td>\n",
              "      <td>000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>708</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>741</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>768</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>802</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>840</td>\n",
              "      <td>which</td>\n",
              "      <td>which</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>868</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>888</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>913</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>946</td>\n",
              "      <td></td>\n",
              "      <td>$</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "      <td>976</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0</td>\n",
              "      <td>1004</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26ce9993-51a9-4aca-a902-50b5811c6a95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26ce9993-51a9-4aca-a902-50b5811c6a95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26ce9993-51a9-4aca-a902-50b5811c6a95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1cf8f168-6092-45b4-9b2e-b14c0c03df2f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1cf8f168-6092-45b4-9b2e-b14c0c03df2f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1cf8f168-6092-45b4-9b2e-b14c0c03df2f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_predictions_bills_finetuned = evaluate_bills(cleaned_validation, model=fine_tuned_gpt2)\",\n  \"rows\": 35,\n  \"fields\": [\n    {\n      \"column\": \"bill_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_text_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 300,\n        \"min\": 15,\n        \"max\": 1004,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual_next_word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_next_word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \" fiscal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_prediction\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bill 0 accuracy: 57.14%\n",
            "\n",
            "Overall accuracy for all bills: 57.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIe_7_E0O1Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eEmZcx-3ML6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimenting to see the training input for fine tuning model"
      ],
      "metadata": {
        "id": "xCb-hKzgPX98"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tokenize fn returning res:  {'input_ids': [[220, 220, 220, 17318, 264, 2078, 2425, 318, 25, 2260, 4860, 10986, 13902, 290, 9025, 719, 286, 1946, 334, 13, 82, 13, 34548, 1946, 12, 2931, 12, 1507, 2420, 14, 19875, 551, 12997, 284, 3670, 1596, 2665, 13343, 286, 262, 16503, 2585, 2438, 11, 428, 2393, 318, 407, 2426, 284, 6634, 4800, 290, 318, 287, 262, 1171, 7386, 13, 220, 220, 220, 220, 220, 21065, 220, 220, 17318, 400, 8681, 17, 67, 6246, 220, 220, 264, 13, 2579, 2425, 220, 220, 287, 262, 34548, 286, 262, 16503, 2585, 220, 220, 220, 220, 220, 220, 384, 457, 1491, 1248, 11, 1946, 220, 220, 220, 285, 81, 13, 4123, 488, 5495, 262, 1708, 2855, 26, 543, 373, 1100, 5403, 290, 6412, 284, 262, 5583, 319, 6936, 2594, 220, 220, 220, 220, 220, 257, 2855, 220, 220, 284, 14873, 1958, 287, 1099, 262, 9323, 290, 10741, 286, 262, 2607, 286, 3716, 11553, 220, 220, 220, 220, 10986, 287, 262, 2260, 4860, 10583, 11, 290, 329, 584, 4959, 13, 220, 220, 220, 352, 13, 19509, 3670, 5661, 719, 743, 307, 9181, 355, 262, 2260, 4860, 10986, 13902, 290, 9025, 719, 286, 1946, 13, 17, 13, 19815, 2649, 287, 1099, 286, 9323, 290, 10741, 286, 262, 2607, 286, 3716, 11553, 220, 220, 220, 220, 10986, 287, 262, 2260, 4860, 10583, 7, 64, 8, 259, 2276, 8117, 318, 287, 262, 2607, 286, 262, 4039, 286, 262, 2260, 4860, 10583, 262, 2607, 286, 3716, 220, 220, 220, 220, 11553, 10986, 357, 259, 428, 2665, 6412, 284, 355, 262, 2607, 737, 7, 65, 8, 37295, 290, 20865, 1169, 2607, 2236, 307, 739, 262, 4571, 290, 20865, 286, 262, 4039, 286, 262, 2260, 4860, 220, 220, 220, 220, 10583, 12195, 66, 8, 67, 8249, 7, 16, 8, 259, 2276, 1169, 10741, 286, 262, 2607, 2236, 307, 284, 25340, 3716, 11553, 10986, 286, 6067, 220, 220, 220, 220, 11270, 284, 1866, 286, 262, 2260, 4860, 618, 287, 1181, 3722, 11, 1390, 220, 220, 220, 220, 10986, 286, 3206, 4641, 7411, 257, 2888, 286, 262, 2260, 4860, 220, 220, 220, 220, 287, 884, 3722, 11, 2402, 262, 2581, 286, 597, 286, 262, 1708, 37498, 64, 8, 1169, 4039, 286, 262, 2260, 4860, 10583, 12195, 65, 8, 272, 9224, 315, 415, 2276, 286, 257, 1181, 393, 7674, 393, 262, 4783, 286, 951, 2178, 544, 12195, 66, 8, 1169, 8153, 220, 286, 257, 1181, 393, 7674, 11, 393, 262, 25771, 2276, 286, 262, 2260, 4860, 286, 262, 220, 220, 220, 220, 4783, 286, 951, 2178, 544, 12195, 17, 8, 41887, 11553, 10986, 1640, 4959, 286, 428, 8371, 11, 257, 3716, 11553, 3645, 318, 597, 3645, 357, 292, 220, 220, 220, 220, 7368, 416, 262, 4039, 286, 262, 2260, 4860, 10583, 329, 4959, 220, 220, 220, 220, 286, 428, 2665, 8, 7411, 5087, 3501, 4485, 284, 8468, 13357, 287, 220, 220, 220, 220, 3645, 11, 1390, 262, 1708, 37498, 64, 8, 6138, 507, 286, 12934, 1022, 262, 16503, 2585, 290, 257, 1181, 393, 7674, 12195, 65, 8, 6759, 1010, 10616, 16976, 3047, 1871, 10240, 3790, 12195, 66, 8, 6759, 1010, 8620, 262, 761, 329, 281, 4795, 3645, 287, 1502, 284, 4155, 22692, 290, 220, 220, 220, 220, 32521, 414, 287, 3645, 12195, 18, 8, 6759, 1010, 11270, 284, 1866, 286, 262, 2260, 4860, 287, 1181, 1185, 436, 258, 12123, 1771, 393, 407, 257, 2300, 18436, 284, 257, 2888, 286, 262, 2260, 4860, 618, 287, 1181, 220, 220, 220, 220, 3722, 329, 4959, 286, 428, 2665, 2236, 307, 925, 416, 262, 4039, 286, 220, 220, 220, 220, 262, 2260, 4860, 10583, 287, 10213, 351, 9987, 7368, 416, 262, 220, 220, 220, 220, 4039, 286, 262, 2260, 4860, 10583, 220, 329, 4959, 286, 428, 2665, 12195, 67, 8, 17351, 286, 2260, 220, 4860, 10583, 3513, 286, 2457, 989, 301, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 220, 2190, 597, 2457, 989, 286, 262, 2607, 319, 257, 2300, 220, 220, 220, 220, 220, 739, 428, 2665, 355, 611, 884, 989, 547, 262, 989, 286, 281, 24110, 220, 220, 220, 220, 2276, 286, 262, 5011, 286, 3761, 393, 257, 2422, 5011, 319, 884, 220, 220, 220, 220, 2300, 12195, 68, 8, 48922, 284, 8681, 7, 16, 8, 7266, 20124, 282, 286, 2457, 3136, 284, 11702, 8570, 602, 27287, 262, 12695, 416, 262, 2607, 286, 257, 2457, 989, 319, 281, 3645, 21846, 416, 262, 2607, 220, 220, 220, 220, 12997, 284, 428, 2665, 11, 262, 4039, 286, 262, 2260, 4860, 10583, 2236, 220, 220, 220, 220, 9199, 884, 989, 357, 4480, 597, 7620, 13720, 1321, 220, 220, 220, 220, 20431, 44740, 8],\n",
        " [284, 262, 1866, 286, 8681, 422, 262, 1181, 393, 220, 220, 220, 220, 7674, 5213, 12195, 17, 8, 1236, 723, 989, 301, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 9199, 284, 8681, 1123, 614, 257, 989, 319, 262, 220, 220, 220, 220, 10986, 21846, 416, 262, 2607, 12997, 284, 428, 2665, 1141, 220, 220, 220, 220, 262, 18148, 614, 13, 1123, 989, 2236, 2291, 11, 329, 262, 614, 5017, 416, 220, 220, 220, 220, 884, 989, 11, 220, 262, 1708, 37498, 64, 8, 64, 10638, 6764, 286, 262, 220, 220, 220, 220, 10986, 21846, 1141, 884, 614, 11, 220, 220, 220, 220, 1390, 597, 11257, 287, 6067, 2426, 284, 3645, 290, 287, 6373, 220, 220, 220, 220, 355, 257, 1255, 286, 10986, 12195, 65, 8, 17018, 11],\n",
        "  [900, 6071, 416, 1181, 290, 7674, 11, 319, 262, 10986, 21846, 1141, 884, 614, 220, 220, 220, 220, 7411, 7636, 286, 3206, 4641, 7411, 257, 2888, 286, 262, 2260, 220, 220, 220, 220, 4860, 12195, 66, 8, 10508, 584, 1321, 290, 6067, 319, 262, 10986, 21846, 1141, 884, 614, 355, 262, 4039, 220, 220, 220, 220, 286, 262, 2260, 4860, 10583, 14358, 5035, 12195, 69, 8, 6259, 4954, 290, 584, 1451, 397, 6392, 6386, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 4155, 326, 262, 2607, 16047, 262, 8213, 220, 220, 220, 220, 290, 584, 9889, 3306, 329, 262, 17655, 286, 262, 10741],\n",
        "   [286, 262, 220, 220, 220, 220, 2607, 739, 428, 2665, 12195, 70, 8, 1676, 771, 942, 290, 12064, 301, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 2071, 11, 290, 743, 422, 640, 284, 640, 4296, 11, 220, 220, 220, 220, 9021, 290, 7729, 3306, 329, 262, 17655, 286, 262, 10741, 286, 220, 220, 220, 220, 262, 2607, 739, 428, 2665, 12195, 71, 8, 45956, 282, 286, 22754, 15395, 12064, 17351, 286, 262, 2260, 4860, 10583, 12064, 269, 782, 8482, 657, 7029, 13, 486, 11, 14567, 474, 2062, 1542, 11, 2321, 11, 2236, 423, 645, 220, 220, 220, 220, 2252, 2700, 393, 1245, 13]],\n",
        "                             'labels': [[220, 220, 220, 17318, 264, 2078, 2425, 318, 25, 2260, 4860, 10986, 13902, 290, 9025, 719, 286, 1946, 334, 13, 82, 13, 34548, 1946, 12, 2931, 12, 1507, 2420, 14, 19875, 551, 12997, 284, 3670, 1596, 2665, 13343, 286, 262, 16503, 2585, 2438, 11, 428, 2393, 318, 407, 2426, 284, 6634, 4800, 290, 318, 287, 262, 1171, 7386, 13, 220, 220, 220, 220, 220, 21065, 220, 220, 17318, 400, 8681, 17, 67, 6246, 220, 220, 264, 13, 2579, 2425, 220, 220, 287, 262, 34548, 286, 262, 16503, 2585, 220, 220, 220, 220, 220, 220, 384, 457, 1491, 1248, 11, 1946, 220, 220, 220, 285, 81, 13, 4123, 488, 5495, 262, 1708, 2855, 26, 543, 373, 1100, 5403, 290, 6412, 284, 262, 5583, 319, 6936, 2594, 220, 220, 220, 220, 220, 257, 2855, 220, 220, 284, 14873, 1958, 287, 1099, 262, 9323, 290, 10741, 286, 262, 2607, 286, 3716, 11553, 220, 220, 220, 220, 10986, 287, 262, 2260, 4860, 10583, 11, 290, 329, 584, 4959, 13, 220, 220, 220, 352, 13, 19509, 3670, 5661, 719, 743, 307, 9181, 355, 262, 2260, 4860, 10986, 13902, 290, 9025, 719, 286, 1946, 13, 17, 13, 19815, 2649, 287, 1099, 286, 9323, 290, 10741, 286, 262, 2607, 286, 3716, 11553, 220, 220, 220, 220, 10986, 287, 262, 2260, 4860, 10583, 7, 64, 8, 259, 2276, 8117, 318, 287, 262, 2607, 286, 262, 4039, 286, 262, 2260, 4860, 10583, 262, 2607, 286, 3716, 220, 220, 220, 220, 11553, 10986, 357, 259, 428, 2665, 6412, 284, 355, 262, 2607, 737, 7, 65, 8, 37295, 290, 20865, 1169, 2607, 2236, 307, 739, 262, 4571, 290, 20865, 286, 262, 4039, 286, 262, 2260, 4860, 220, 220, 220, 220, 10583, 12195, 66, 8, 67, 8249, 7, 16, 8, 259, 2276, 1169, 10741, 286, 262, 2607, 2236, 307, 284, 25340, 3716, 11553, 10986, 286, 6067, 220, 220, 220, 220, 11270, 284, 1866, 286, 262, 2260, 4860, 618, 287, 1181, 3722, 11, 1390, 220, 220, 220, 220, 10986, 286, 3206, 4641, 7411, 257, 2888, 286, 262, 2260, 4860, 220, 220, 220, 220, 287, 884, 3722, 11, 2402, 262, 2581, 286, 597, 286, 262, 1708, 37498, 64, 8, 1169, 4039, 286, 262, 2260, 4860, 10583, 12195, 65, 8, 272, 9224, 315, 415, 2276, 286, 257, 1181, 393, 7674, 393, 262, 4783, 286, 951, 2178, 544, 12195, 66, 8, 1169, 8153, 220, 286, 257, 1181, 393, 7674, 11, 393, 262, 25771, 2276, 286, 262, 2260, 4860, 286, 262, 220, 220, 220, 220, 4783, 286, 951, 2178, 544, 12195, 17, 8, 41887, 11553, 10986, 1640, 4959, 286, 428, 8371, 11, 257, 3716, 11553, 3645, 318, 597, 3645, 357, 292, 220, 220, 220, 220, 7368, 416, 262, 4039, 286, 262, 2260, 4860, 10583, 329, 4959, 220, 220, 220, 220, 286, 428, 2665, 8, 7411, 5087, 3501, 4485, 284, 8468, 13357, 287, 220, 220, 220, 220, 3645, 11, 1390, 262, 1708, 37498, 64, 8, 6138, 507, 286, 12934, 1022, 262, 16503, 2585, 290, 257, 1181, 393, 7674, 12195, 65, 8, 6759, 1010, 10616, 16976, 3047, 1871, 10240, 3790, 12195, 66, 8, 6759, 1010, 8620, 262, 761, 329, 281, 4795, 3645, 287, 1502, 284, 4155, 22692, 290, 220, 220, 220, 220, 32521, 414, 287, 3645, 12195, 18, 8, 6759, 1010, 11270, 284, 1866, 286, 262, 2260, 4860, 287, 1181, 1185, 436, 258, 12123, 1771, 393, 407, 257, 2300, 18436, 284, 257, 2888, 286, 262, 2260, 4860, 618, 287, 1181, 220, 220, 220, 220, 3722, 329, 4959, 286, 428, 2665, 2236, 307, 925, 416, 262, 4039, 286, 220, 220, 220, 220, 262, 2260, 4860, 10583, 287, 10213, 351, 9987, 7368, 416, 262, 220, 220, 220, 220, 4039, 286, 262, 2260, 4860, 10583, 220, 329, 4959, 286, 428, 2665, 12195, 67, 8, 17351, 286, 2260, 220, 4860, 10583, 3513, 286, 2457, 989, 301, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 220, 2190, 597, 2457, 989, 286, 262, 2607, 319, 257, 2300, 220, 220, 220, 220, 220, 739, 428, 2665, 355, 611, 884, 989, 547, 262, 989, 286, 281, 24110, 220, 220, 220, 220, 2276, 286, 262, 5011, 286, 3761, 393, 257, 2422, 5011, 319, 884, 220, 220, 220, 220, 2300, 12195, 68, 8, 48922, 284, 8681, 7, 16, 8, 7266, 20124, 282, 286, 2457, 3136, 284, 11702, 8570, 602, 27287, 262, 12695, 416, 262, 2607, 286, 257, 2457, 989, 319, 281, 3645, 21846, 416, 262, 2607, 220, 220, 220, 220, 12997, 284, 428, 2665, 11, 262, 4039, 286, 262, 2260, 4860, 10583, 2236, 220, 220, 220, 220, 9199, 884, 989, 357, 4480, 597, 7620, 13720, 1321, 220, 220, 220, 220, 20431, 44740, 8],\n",
        " [284, 262, 1866, 286, 8681, 422, 262, 1181, 393, 220, 220, 220, 220, 7674, 5213, 12195, 17, 8, 1236, 723, 989, 301, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 9199, 284, 8681, 1123, 614, 257, 989, 319, 262, 220, 220, 220, 220, 10986, 21846, 416, 262, 2607, 12997, 284, 428, 2665, 1141, 220, 220, 220, 220, 262, 18148, 614, 13, 1123, 989, 2236, 2291, 11, 329, 262, 614, 5017, 416, 220, 220, 220, 220, 884, 989, 11, 220, 262, 1708, 37498, 64, 8, 64, 10638, 6764, 286, 262, 220, 220, 220, 220, 10986, 21846, 1141, 884, 614, 11, 220, 220, 220, 220, 1390, 597, 11257, 287, 6067, 2426, 284, 3645, 290, 287, 6373, 220, 220, 220, 220, 355, 257, 1255, 286, 10986, 12195, 65, 8, 17018, 11],\n",
        " [900, 6071, 416, 1181, 290, 7674, 11, 319, 262, 10986, 21846, 1141, 884, 614, 220, 220, 220, 220, 7411, 7636, 286, 3206, 4641, 7411, 257, 2888, 286, 262, 2260, 220, 220, 220, 220, 4860, 12195, 66, 8, 10508, 584, 1321, 290, 6067, 319, 262, 10986, 21846, 1141, 884, 614, 355, 262, 4039, 220, 220, 220, 220, 286, 262, 2260, 4860, 10583, 14358, 5035, 12195, 69, 8, 6259, 4954, 290, 584, 1451, 397, 6392, 6386, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 4155, 326, 262, 2607, 16047, 262, 8213, 220, 220, 220, 220, 290, 584, 9889, 3306, 329, 262, 17655, 286, 262, 10741],\n",
        "  [286, 262, 220, 220, 220, 220, 2607, 739, 428, 2665, 12195, 70, 8, 1676, 771, 942, 290, 12064, 301, 258, 4039, 286, 262, 2260, 4860, 10583, 2236, 2071, 11, 290, 743, 422, 640, 284, 640, 4296, 11, 220, 220, 220, 220, 9021, 290, 7729, 3306, 329, 262, 17655, 286, 262, 10741, 286, 220, 220, 220, 220, 262, 2607, 739, 428, 2665, 12195, 71, 8, 45956, 282, 286, 22754, 15395, 12064, 17351, 286, 262, 2260, 4860, 10583, 12064, 269, 782, 8482, 657, 7029, 13, 486, 11, 14567, 474, 2062, 1542, 11, 2321, 11, 2236, 423, 645, 220, 220, 220, 220, 2252, 2700, 393, 1245, 13]]}\n"
      ],
      "metadata": {
        "id": "YedzWSdeMTIa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}