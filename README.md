# LegalAIze
A word prediction (sentence autocomplete) model for the Legal Domain. The project aims to create a next-word prediction tool by fine-tuning existing language models (GPT-2 and BERT) on legal texts.


This repository contains the pre-processing, training, and fine-tuning code for the Next Word Prediction task.

- Baseline Model: Contains the evaluation for the Baseline Model (SOTA), LegalBERT using the two metrics - (i) accuracy and (ii) top-k accuracy
- Fine-tuned Model: Contains the evaluations for the two chosen LMs (GPT-2 and BERT) using the same metrics
- Final Report describing the project background, motivation, methodology, experiments, results, and conclusions.
